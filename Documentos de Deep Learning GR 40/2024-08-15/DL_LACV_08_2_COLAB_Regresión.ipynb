{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7L1u5m7vGPH"
      },
      "source": [
        "# Aprendizaje Automático - Regresión paramétrica\n",
        "\n",
        "Autor: Saúl Calderón, Juan Esquivel, Luis-Alexander Calvo-Valverde"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWClLAjfvtAA"
      },
      "source": [
        "# Regresión Paramétrica\n",
        "A continuación se retoman conceptos relacionados con  encontrar los pesos ideales para minimizar el error en una regresión."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPD8sqQXo3_P"
      },
      "source": [
        "## El problema de ajuste de curvas\n",
        "\n",
        "El objetivo del ajuste de curvas es encontrar un modelo que se ajuste al conjunto de observaciones $\\mathcal{D}=\\left\\{ \\vec{x},\\vec{t}\\right\\} $, y que posibilite la predicción de de la salida $t$ para una nueva muestra $x$.\n",
        "\n",
        "En este trabajo práctico estudiaremos un **modelo con pesos lineales respecto al vector de pesos o parámetros del modelo $\\vec{w}$** con funciones base polinomiales, de la forma:\n",
        "\n",
        "\\begin{equation}\n",
        "y(x,\\vec{w})=w_{0}+w_{1}x+w_{2}x^{2}+\\ldots+w_{M}x^{M}=\\sum_{j=0}^{M}w_{j}x^{j}\n",
        "\\end{equation}\n",
        "  \n",
        "por lo que $\\vec{w}\\in\\mathbb{R}^{M+1}$, definiendo $M+1$ la dimensionalidad\n",
        "del modelo, y constituyendo la cantidad de parámetros desconocidos\n",
        "a estimar. Observe que la regresión lineal es un caso particular de\n",
        "la regresión polinomial con $M=1$:\n",
        "  \n",
        "\\begin{equation}\n",
        "y(x,\\vec{w})=w_{0}+w_{1}x=\\sum_{j=0}^{1}w_{j}x^{j}\n",
        "\\end{equation}\n",
        "\n",
        "En general, si otras funciones base distintas a $\\phi_{j}(x)=x^{j}$\n",
        "son usadas, la expresión del modelo viene dada por:\n",
        "  \n",
        "\\begin{equation}\n",
        "y(x,\\vec{w})=\\sum_{j=0}^{M}w_{j}\\phi_{j}(x)\n",
        "\\end{equation}\n",
        "  \n",
        "\\begin{equation}\n",
        "\\Rightarrow y(x,\\vec{w})=\\vec{w}\\cdot\\vec{\\phi}(x)\n",
        "\\end{equation}\n",
        "  \n",
        "donde el conjunto de funcionales $\\{\\phi_{1}(x),\\phi_{2}(x),\\ldots,\\phi_{M}(x)\\}$\n",
        "se le denomina conjunto base, o **conjunto de funciones base**.\n",
        "\n",
        "En los modelos lineales, el orden viene dado por la cantidad de términos\n",
        "en la combinación lineal $M$, el cual define la complejidad del modelo.\n",
        "Una vez definido el modelo a implementar (lineal o no lineal, conjunto\n",
        "de funciones base), el problema general de ajuste de modelo al conjunto\n",
        "de observaciones $\\mathcal{D}=\\left\\{ \\vec{x},\\vec{t}\\right\\} $ se\n",
        "reduce a determinar el valor de los pesos $\\vec{w}$. Un enfoque sencillo\n",
        "para calcular los valores de $\\vec{w}$ óptimos es el de **mínimos\n",
        "cuadrados**, el cual propone la expresión de la función de error como\n",
        "sigue:\n",
        "\n",
        "\\begin{equation}\n",
        "E(\\vec{w})=\\frac{1}{2}\\sum_{n=0}^{N}\\left\\{ y\\left(x_{n},\\vec{w}\\right)-t_{n}\\right\\} ^{2}=\\frac{1}{2}\\sum_{n=1}^{N}\\left\\{ \\sum_{j=0}^{M}w_{j}x_{n}^{j}-t_{n}\\right\\} ^{2}\n",
        "\\end{equation}\n",
        "\n",
        "En tal esquema de mínimos cuadrados, el error se define entonces en\n",
        "como la diferencia al cuadrado de la evaluación del modelo en cada\n",
        "muestra de $\\vec{x}=\\left[x_{0},...,.x_{N}\\right]^{T}$ con cada uno\n",
        "de las muestras de su salida $\\vec{t}=\\left[t_{0},...,.t_{N}\\right]^{T}$\n",
        "usando entonces el conjunto de datos de entrenamiento $\\mathcal{D}=\\left\\{ \\vec{x},\\vec{t}\\right\\} $.\n",
        "  \n",
        "  \n",
        "Nótese que es posible **utilizar otras funciones de error** como,\n",
        "por ejemplo, la diferencia absoluta. El enfoque de mínimos cuadrados\n",
        "propone minimizar la expresión de error propuesta en la ecuación anterior,\n",
        "por cada uno de los pesos en el vector $\\vec{w}$. Para ello, dicha ecuación\n",
        "es derivada parcialmente respecto a $w_{i}$ e igualada\n",
        "a cero:\n",
        "\n",
        "\\begin{equation}\n",
        "\\frac{\\partial E\\left(\\vec{w}\\right)}{w_{i}}=\\sum_{n=1}^{N}\\left\\{ \\sum_{j=0}^{M}w_{j}x_{n}^{j}-t_{n}\\right\\} x_{n}^{i}=0\n",
        "\\end{equation}\n",
        "\n",
        "Despejando entonces la expresión, se obtiene un conjunto de $M+1$ ecuaciones $(i=0,1,2,3,\\ldots,M)$ donde los valores $w_{j}$ son desconocidos, por lo que para una ecuación $i$ tenemos:\n",
        "\n",
        "\\begin{equation}\n",
        "\\sum_{n=1}^{N}\\sum_{j=0}^{M}w_{j}x_{n}^{j+i}=\\sum_{n=0}^{N}t_{n}x_{n}^{i}\n",
        "\\end{equation}\n",
        "y cambiando el orden a las sumatorias se obtiene:\n",
        "\n",
        "\\begin{equation}\n",
        "\\sum_{j=0}^{M}\\sum_{n=1}^{N}w_{j}x_{n}^{j+i}=\\sum_{n=0}^{N}t_{n}x_{n}^{i}\n",
        "\\end{equation}\n",
        " Desarrollando el sistema de matrices en la ecuación anterior, **para\n",
        "los $M$ pesos**, obtenemos la siguiente expresión:\n",
        "\n",
        "\\begin{equation}\n",
        "\\begin{array}[t]{c}\n",
        "\\left(i=0\\right)\\qquad w_{0}\\sum_{n=1}^{N}1+w_{1}\\sum_{n=1}^{N}x_{n}+w_{2}\\sum_{n=1}^{N}x_{n}^{2}+\\ldots+w_{M}\\sum_{n=1}^{N}x_{n}^{M}=\\sum_{n=1}^{N}t_{n}\\\\\n",
        "\\left(i=1\\right)\\qquad w_{0}\\sum_{n=1}^{N}x_{n}+w_{1}\\sum_{n=1}^{N}x_{n}^{2}+w_{2}\\sum_{n=1}^{N}x_{n}^{3}+\\ldots+w_{M}\\sum_{n=1}^{N}x_{n}^{M+1}=\\sum_{n=1}^{N}x_{n}t_{n}\\\\\n",
        "\\left(i=2\\right)\\qquad w_{0}\\sum_{n=1}^{N}x_{n}^{2}+w_{1}\\sum_{n=1}^{N}x_{n}^{3}+w_{2}\\sum_{n=1}^{N}x_{n}^{4}+\\ldots+w_{M}\\sum_{n=1}^{N}x_{n}^{M+2}=\\sum_{n=1}^{N}x_{n}^{2}t_{n}\\\\\n",
        "\\vdots\\\\\n",
        "\\left(i=M\\right)\\qquad w_{0}\\sum_{n=1}^{N}x_{n}^{M}+w_{1}\\sum_{n=1}^{N}x_{n}^{M+1}+w_{2}\\sum_{n=1}^{N}x_{n}^{M+2}+\\ldots+w_{M}\\sum_{n=1}^{N}x_{n}^{2M}=\\sum_{n=1}^{N}x_{n}^{M}t_{n}\n",
        "\\end{array}\n",
        "\\end{equation}\n",
        "\n",
        "Los valores $w_{j}$ obtenidos al resolver este sistema de ecuaciones\n",
        "anterior se representan en el vector de pesos óptimo $\\vec{w}_{\\textrm{opt}}$.\n",
        "\n",
        "En términos matriciales, lo anterior se desarrolla como:\n",
        "  \n",
        "$\n",
        "\\begin{bmatrix}\\sum_{n=1}^{N}1 & \\sum_{n=1}^{N}x_{n} & \\sum_{n=1}^{N}x_{n}^{2} & \\ldots & \\sum_{n=1}^{N}x_{n}^{M}\\\\\n",
        "\\sum_{n=1}^{N}x_{n} & \\sum_{n=1}^{N}x_{n}^{2} & \\sum_{n=1}^{N}x_{n}^{3} &  & \\sum_{n=1}^{N}x_{n}^{M+1}\\\\\n",
        "\\sum_{n=1}^{N}x_{n}^{2} & \\sum_{n=1}^{N}x_{n}^{3} & \\sum_{n=1}^{N}x_{n}^{4} &  & \\sum_{n=1}^{N}x_{n}^{M+2}\\\\\n",
        " &  & \\vdots\\\\\n",
        "\\sum_{n=1}^{N}x_{n}^{M} & \\sum_{n=1}^{N}x_{n}^{M+1} & \\sum_{n=1}^{N}x_{n}^{M+2} &  & \\sum_{n=1}^{N}x_{n}^{2M}\n",
        "\\end{bmatrix}\\:\\vec{w}=\\begin{bmatrix}\\sum_{n=1}^{N}t_{n}\\\\\n",
        "\\sum_{n=1}^{N}x_{n}t_{n}\\\\\n",
        "\\sum_{n=1}^{N}x_{n}^{2}t_{n}\\\\\n",
        "\\vdots\\\\\n",
        "\\sum_{n=1}^{N}x_{n}^{M}t_{n}\n",
        "\\end{bmatrix}\n",
        "$\n",
        "  \n",
        "Para lo cual, si $A$ es la primer matriz de izquierda a derecha,\n",
        "y $B$ la matriz al lado derecho de la igualdad, se tiene que:\n",
        "  \n",
        "$$\n",
        "\\vec{w}_{\\textrm{opt}}=A^{-1}\\:B\n",
        "$$\n",
        "\n",
        "Para evaluar el error resultante de ajustar un modelo de dimensión\n",
        "$M$ y con pesos $\\vec{w}_{\\textrm{opt}}$, se utiliza el error normalizado\n",
        "o **error RMS**, expresado como sigue:\n",
        "\n",
        "\\begin{equation}\n",
        "E\\left(\\vec{w}_{\\textrm{opt}}\\right)_{\\textrm{RMS}}=\\sqrt{2E\\left(\\vec{w}_{\\textrm{opt}}\\right)/N}.\n",
        "\\end{equation}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVvaYZkfrJvY"
      },
      "source": [
        "## Mínimos cuadrados regularizado\n",
        "\n",
        "La expresión de error regularizada agrega un término $\\frac{\\lambda}{2}\\left\\Vert \\vec{w}\\right\\Vert _{2}^{2}$\n",
        "con magnitud $\\ell=2$, para controlar la magnitud del vector de pesos\n",
        "$\\vec{w}$ y su dimensionalidad, de forma más simple:\n",
        "\n",
        "\\begin{equation}\n",
        "E(\\vec{w})=\\frac{1}{2}\\sum_{n=1}^{N}\\left\\{ y\\left(x_{n},\\vec{w}\\right)-t_{n}\\right\\} ^{2}+\\frac{\\lambda}{2}\\left\\Vert \\vec{w}\\right\\Vert ^{2}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "E(\\vec{w})=\\frac{1}{2}\\sum_{n=1}^{N}\\left\\{ \\sum_{j=0}^{M}w_{j}x_{n}^{j}-t_{n}\\right\\} ^{2}+\\frac{\\lambda}{2}\\left\\Vert \\vec{w}\\right\\Vert ^{2}\n",
        "\\end{equation}\n",
        "\n",
        "En términos matriciales, se define\n",
        "\n",
        "\\begin{equation}\n",
        "X=\\begin{bmatrix}1 & x_{1} & x_{1}^{2} & x_{1}^{3} & \\ldots & x_{1}^{M}\\\\\n",
        "1 & x_{2} & x_{2}^{2} & x_{2}^{3} & \\ldots & x_{2}^{M}\\\\\n",
        "1 & x_{3} & x_{3}^{2} & x_{3}^{3} & \\cdots & x_{3}^{M}\\\\\n",
        "\\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
        "1 & x_{N} & x_{N}^{2} & x_{N}^{3} & \\ldots & x_{N}^{M}\n",
        "\\end{bmatrix},\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "para el caso del modelo polinomial, por lo que $X$ es de dimensiones\n",
        "$\\mathbb{R}^{N\\times M}$, $\\vec{t}$ de $\\mathbb{R}^{N\\times1}$\n",
        "y $\\vec{w}\\in\\mathbb{R}^{M\\times1}$ . Recordando además que la norma\n",
        "al cuadrado de un vector como $\\left\\Vert \\vec{w}\\right\\Vert ^{2}=\\vec{w}^{T}\\,\\vec{w}$.\n",
        "Se puede reescribir matricialmente la salida del modelo definido en\n",
        "la sección de ajuste de curvas como:\n",
        "\n",
        "\\begin{equation}\n",
        "y(X,\\vec{w})=X\\,\\vec{w}=\\begin{bmatrix}1 & x_{1} & x_{1}^{2} & x_{1}^{3} & \\ldots & x_{1}^{M}\\\\\n",
        "1 & x_{2} & x_{2}^{2} & x_{2}^{3} & \\ldots & x_{2}^{M}\\\\\n",
        "1 & x_{3} & x_{3}^{2} & x_{3}^{3} & \\cdots & x_{3}^{M}\\\\\n",
        "\\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
        "1 & x_{N} & x_{N}^{2} & x_{N}^{3} & \\ldots & x_{N}^{M}\n",
        "\\end{bmatrix}\\,\\begin{bmatrix}w_{0}\\\\\n",
        "w_{1}\\\\\n",
        "\\vdots\\\\\n",
        "w_{M}\n",
        "\\end{bmatrix}=\\begin{bmatrix}\\sum_{m=0}^{M}w_{m}\\:x_{1}^{m}\\\\\n",
        "\\sum_{m=0}^{M}w_{m}\\:x_{2}^{m}\\\\\n",
        "\\sum_{m=0}^{M}w_{m}\\:x_{3}^{m}\\\\\n",
        "\\vdots\\\\\n",
        "\\sum_{m=0}^{M}w_{m}\\:x_{N}^{m}\n",
        "\\end{bmatrix},\n",
        "\\end{equation}\n",
        "\n",
        "y la ecuación con regularización es reescrita en términos matriciales:\n",
        "\n",
        "\\begin{equation}\n",
        "E\\left(\\vec{w}\\right)=\\frac{1}{2}\\left\\Vert X\\,\\vec{w}-\\vec{t}\\right\\Vert ^{2}+\\frac{\\lambda}{2}\\left\\Vert \\vec{w}\\right\\Vert ^{2}=\\frac{1}{2}\\left(X\\,\\vec{w}-\\vec{t}\\right)^{T}\\left(X\\,\\vec{w}-\\vec{t}\\right)+\\frac{\\lambda}{2}\\vec{w}^{T}\\,\\vec{w}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "\\Rightarrow E\\left(\\vec{w}\\right)=\\frac{1}{2}\\left(\\vec{w}^{T}X^{T}-\\vec{t}^{T}\\right)\\left(X\\,\\vec{w}-\\vec{t}\\right)+\\frac{\\lambda}{2}\\vec{w}^{T}\\,\\vec{w}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "\\Rightarrow E\\left(\\vec{w}\\right)=\\frac{1}{2}\\vec{w}^{T}X^{T}X\\,\\vec{w}-\\frac{1}{2}\\vec{w}^{T}X^{T}\\vec{t}-\\frac{1}{2}\\vec{t}^{T}X\\,\\vec{w}+\\frac{1}{2}\\vec{t}^{T}\\,\\vec{t}+\\frac{\\lambda}{2}\\vec{w}^{T}\\,\\vec{w}\n",
        "\\end{equation}\n",
        "\n",
        "Calculando el gradiente de $\\vec{w}$ e igualando a cero, para encontrar\n",
        "el mínimo error, para lo cual recordamos las reglas básicas del cálculo\n",
        "matricial:\n",
        "\n",
        "\n",
        "* $\\nabla_{\\vec{x}}\\left(\\vec{x}^{T}\\vec{x}\\right)=2\\,\\vec{x}$\n",
        "* $\\nabla_{\\vec{x}}\\left(\\left(A\\,\\vec{x}\\right)^{T}\\left(A\\,\\vec{x}\\right)\\right)=2\\,A\\,\\vec{x}$\n",
        "*  $\\nabla_{\\vec{x}}\\left(\\vec{b}^{T}\\vec{x}\\right)=\\vec{b}$\n",
        "* $\\nabla_{\\vec{x}}\\left(\\vec{x}^{T}\\vec{b}^{T}\\right)=\\nabla_{\\vec{x}}\\left(\\vec{b}\\,\\vec{x}\\right)^{T}=\\vec{b}^{T}$\n",
        "* $\\nabla_{\\vec{x}}\\left(\\vec{x}^{T}\\,A\\,\\vec{x}\\right)=2\\,A\\,\\vec{x}$\n",
        "\n",
        "\n",
        "la ecuación matricial se convierte en:\n",
        "\n",
        "\\begin{equation}\n",
        "\\nabla_{\\vec{w}}\\left(E\\left(\\vec{w}\\right)\\right)=0\\Rightarrow\\nabla_{\\vec{w}}\\left(\\frac{1}{2}\\vec{w}^{T}X^{T}X\\,\\vec{w}-\\frac{1}{2}\\vec{w}^{T}X^{T}\\vec{t}-\\frac{1}{2}\\vec{t}^{T}X\\,\\vec{w}+\\frac{\\lambda}{2}\\vec{w}^{T}\\,\\vec{w},\\right)=0,\n",
        "\\end{equation}\n",
        "\n",
        "evaluando el gradiente:\n",
        "\n",
        "\\begin{equation}\n",
        "X^{T}X\\,\\vec{w}-\\frac{1}{2}X^{T}\\vec{t}-\\frac{1}{2}X^{T}\\vec{t}+\\lambda\\vec{w}=0,\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "\\nabla_{\\vec{w}}\\left(E\\left(\\vec{w}\\right)\\right)=X^{T}X\\,\\vec{w}-X^{T}\\vec{t}+\\lambda\\vec{w}=0,\n",
        "\\end{equation}\n",
        "\n",
        "que equivale a:\n",
        "\n",
        "\\begin{equation}\n",
        "\\left(X^{T}X+\\lambda I\\right)\\vec{w}=X^{T}\\vec{t},\n",
        "\\end{equation}\n",
        "\n",
        "para finalmente obtener la expresión de $\\vec{w}$:\n",
        "\\begin{equation}\n",
        "\\vec{w}=\\left(X^{T}X+\\lambda I\\right)^{-1}X^{T}\\vec{t}.\n",
        "\\end{equation}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6eHcLXx8DOK"
      },
      "source": [
        "### Regresión Ridge\n",
        "\n",
        "La regresión Ridge implementa una penalización de achicamiento $\\ell=2$,\n",
        "con $\\vec{w}\\in\\mathbb{R}^{M-1}$\n",
        "\n",
        "\\begin{equation}\n",
        "E(\\vec{w})=\\frac{1}{2}\\sum_{n=1}^{N}\\left\\{ y\\left(x_{n},\\vec{w}\\right)-t_{n}\\right\\} ^{2}+\\frac{\\lambda}{2}\\left\\Vert \\vec{w}\\right\\Vert _{2}^{2}\n",
        "\\end{equation}\n",
        "\n",
        "donde en este caso el sesgo $\\beta$ no es regularizado, de estar\n",
        "forma el sesgo queda libre e independiente del coeficiente de regularización\n",
        "$\\lambda$, por lo que usualmente cuando $\\lambda\\rightarrow\\infty$,\n",
        "el sesgo tiende también a crecer $\\beta\\rightarrow\\infty$. Cuando\n",
        "$\\lambda\\rightarrow\\infty$ la flexibilidad o varianza del modelo\n",
        "$y\\left(x_{n},\\vec{w}\\right)$ tiende a decrecer, lo que se conoce\n",
        "como el **intercambio entre varianza y sesgo**. Una cantidad\n",
        "alta de parámetros $M\\rightarrow\\infty$ hará que **todos los\n",
        "coeficientes se achiquen** con un $\\lambda$ adecuado, por lo que la\n",
        "regresión Ridge da un peso similar a todas las muestras $x$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-zIxcbM8gyD"
      },
      "source": [
        "### Regresión  LASSO\n",
        "\n",
        "En la regresión LASSO se implementa una regularización con norma $\\ell=1$\n",
        "($\\left\\Vert \\vec{w}\\right\\Vert _{1}=\\left|\\vec{w}\\right|$). La regresión\n",
        "LASSO (*least absolute shrinkage and selection operator*) permite\n",
        "poner en cero los coeficientes de las dimensiones o características\n",
        "en cada muestra $\\vec{x}$, lo cual permite seleccionar un subconjunto\n",
        "de dimensiones o características específicas. Para ello usaremos el\n",
        "modelo de orden $M=1$ comentado anteriormente,\n",
        "\n",
        "\\begin{equation}\n",
        "y\\left(\\vec{x},W\\right)=\\sum_{i=0}^{D-1}x_{i}W_{i}+\\beta\n",
        "\\end{equation}\n",
        "\n",
        "con regularización por norma $\\ell=1$:\n",
        "\n",
        "\\begin{equation}\n",
        "E(\\vec{w})=\\frac{1}{2}\\sum_{n=1}^{N}\\left\\{ y\\left(\\vec{x}_{n},\\vec{w}\\right)-t_{n}\\right\\} ^{2}+\\lambda\\left|\\vec{w}\\right|\n",
        "\\end{equation}\n",
        "\n",
        "de forma similar con Ridge, LASSO, cuando $\\lambda\\rightarrow\\infty$,\n",
        "los coeficientes se achican. Sin embargo, en el caso de LASSO, la\n",
        "norma $\\ell=1$ tiene el **efecto de forzar a algunos de los\n",
        "pesos a ser exactamente cero** o a ser muy pequeños respecto a los\n",
        "demás coeficientes, cuando $\\lambda$ es lo suficientemente grande.\n",
        "Es por esto que LASSO es utilizado para la **selección de características**.\n",
        "Esto facilita la interpretación de los modelos generados por LASSO,\n",
        "respecto a los modelos generados por Ridge, pues los pesos que tienden\n",
        "a cero indican características que contribuyen poco al modelo."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nysHdpIX4EX",
        "outputId": "05330207-a0af-4cd3-dff5-dd863d6c989f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "97M0T3dtYRH8"
      },
      "outputs": [],
      "source": [
        "# Bibliotecas requeridas\n",
        "import numpy as np\n",
        "from sklearn import linear_model\n",
        "from numpy import genfromtxt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html#sklearn.preprocessing.RobustScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error\n",
        "from sklearn.metrics import r2_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IKrhxvNwXy4N"
      },
      "outputs": [],
      "source": [
        "# Variable para indicar cuántos registros se quieren ver\n",
        "tPrimeros = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d512c7b3-004d-4c4c-bc77-8c09c998c8f5",
        "id": "YegLpqVnXy4N"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de muestras:  501\n",
            "Prmeros y:  [0.]\n",
            "Primeros X:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "# Carga y preparación de datos\n",
        "my_data = genfromtxt('/content/drive/MyDrive/2024-7-Curso_AA/dataset_Facebook.csv', delimiter=';',filling_values=0.0)\n",
        "X = my_data[:,0:-1]\n",
        "cantidad_muestras = len(my_data)\n",
        "print(\"Cantidad de muestras: \", cantidad_muestras)\n",
        "y = my_data[:,-1]\n",
        "print(\"Prmeros y: \", y[0:tPrimeros])\n",
        "print(\"Primeros X: \", X[0:tPrimeros])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9W2UPYKXy4O",
        "outputId": "00f9f59a-6496-4a6a-a727-ad5f490bb602"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tamaño del train:  350\n",
            "\n",
            "Tamaño del test:  151\n"
          ]
        }
      ],
      "source": [
        "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html?highlight=split#sklearn.model_selection.train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, shuffle=True,\n",
        "                                                    random_state=10)\n",
        "print(\"\\nTamaño del train: \", len(X_train))\n",
        "print(\"\\nTamaño del test: \", len(X_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Bf29f7cXy4P",
        "outputId": "85fa9578-017d-473f-ec17-db62eede4210"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Primeros X_train:  [[-0.06329472  0.          0.          0.75        0.25        1.\n",
            "  -0.17330883 -0.18458742 -0.07996894  0.          0.0169863  -0.14541269\n",
            "  -0.11154821 -0.11921459 -0.4        -0.24288425 -0.4137931 ]]\n",
            "Primeros X_test:  [[-0.18810802 -0.5        -0.16666667  0.5         0.375       1.\n",
            "   5.4782359   4.37058853  1.60481366  1.81357318  2.24931507  1.25307113\n",
            "   1.19695778  1.32819074 -0.4        -0.56166983 -0.64367816]]\n"
          ]
        }
      ],
      "source": [
        "# Escalar datos\n",
        "transformer = RobustScaler().fit(X_train)\n",
        "X_train = transformer.transform( X_train)\n",
        "X_test = transformer.transform( X_test)\n",
        "print(\"Primeros X_train: \", X_train[0:tPrimeros])\n",
        "print(\"Primeros X_test: \", X_test[0:tPrimeros])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CZtpe8xEXy4P"
      },
      "outputs": [],
      "source": [
        "def muestreMetricas(py_test, py_pred, psquared):\n",
        "    metrica = mean_squared_error(py_test, py_pred, squared=psquared)\n",
        "    # If True returns MSE value, if False returns RMSE value.\n",
        "    if psquared:\n",
        "        print(\"RMSE: \", metrica)\n",
        "    else:\n",
        "        print(\"MSE: \", metrica)\n",
        "    print(\"R2: \", r2_score(py_test, py_pred) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d58a8fd5-7b86-4bfa-8e77-6b3ed3c91f4c",
        "id": "v7pX2q6hXy4P"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OLSR\n",
            "MSE:  1.2132783233975838e-12\n",
            "R2:  1.0\n",
            "Coeficientes:  [ 1.09185143e-13 -7.10542736e-14 -1.27518179e-13  6.13381039e-14\n",
            " -4.80642744e-14 -3.99328165e-14  6.29660914e-14  8.49320510e-14\n",
            " -1.08047084e-13  4.74234962e-14  5.72148493e-14  1.14453515e-13\n",
            "  4.31232506e-14  8.93523556e-14  5.00000000e+00  1.31750000e+02\n",
            "  2.17500000e+01]\n",
            "Intersección:  117.99999999999972\n"
          ]
        }
      ],
      "source": [
        "print( \"OLSR\")\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
        "reg = linear_model.LinearRegression( fit_intercept=True).fit(X_train, y_train)\n",
        "y_pred = reg.predict(X_test)\n",
        "muestreMetricas(y_test, y_pred, False)\n",
        "print( \"Coeficientes: \", reg.coef_ )\n",
        "print( \"Intersección: \", reg.intercept_ )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0310230-b4f3-4b82-b665-34fdec30f6ab",
        "id": "7LKPqRfLXy4P"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lasso\n",
            "MSE:  1.3195382188484026\n",
            "R2:  0.9999942409022979\n",
            "Coeficientes:  [ -0.           0.          -0.          -0.          -0.\n",
            "   0.           0.           0.           0.           0.\n",
            "   0.           0.           0.           0.           5.06456933\n",
            " 131.90600861  21.04178194]\n",
            "Intersección:  118.07883819475333\n"
          ]
        }
      ],
      "source": [
        "print(\"lasso\")\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso\n",
        "reg = linear_model.Lasso(alpha=0.5,fit_intercept=True).fit(X_train, y_train)\n",
        "y_pred = reg.predict(X_test)\n",
        "muestreMetricas(y_test, y_pred, False)\n",
        "print( \"Coeficientes: \", reg.coef_ )\n",
        "print( \"Intersección: \", reg.intercept_ )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "586dbbd9-41d9-444d-9655-67f5ebe8ba28",
        "id": "4AWcJIreXy4Q"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ridge\n",
            "MSE:  1.0499562121305355\n",
            "R2:  0.9999963536959985\n",
            "Coeficientes:  [ 1.13089578e-01  1.49835843e-01 -1.02355199e-01 -8.43276372e-02\n",
            " -1.17736195e-02  9.10622019e-02  1.22997313e-01 -8.64942236e-02\n",
            "  9.19970905e+00 -8.84468216e+00  6.99477261e-02  4.75318436e-02\n",
            "  1.07448607e-01  1.92040551e-01  5.14850728e+00  1.29427874e+02\n",
            "  2.25380801e+01]\n",
            "Intersección:  118.28446947298808\n"
          ]
        }
      ],
      "source": [
        "print(\"Ridge\")\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge\n",
        "reg = linear_model.Ridge(alpha=1.0, fit_intercept=True).fit(X_train, y_train)\n",
        "y_pred = reg.predict(X_test)\n",
        "muestreMetricas(y_test, y_pred, False)\n",
        "print( \"Coeficientes: \", reg.coef_ )\n",
        "print( \"Intersección: \", reg.intercept_ )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5dea329-5755-4a53-d9cb-f02fdf92b205",
        "id": "3wcmvZl7Xy4Q"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ElasticNet\n",
            "MSE:  43.649542043403095\n",
            "R2:  0.9936981235801713\n",
            "Coeficientes:  [ 2.15375285  5.92728566  1.98607754 -1.0986137   0.          0.92954468\n",
            "  9.53973548 -3.69723989  7.87931298 -6.66487042 -4.93102621  1.64550241\n",
            " 11.98066939  5.25342491 14.39108689 90.40050417 33.22150735]\n",
            "Intersección:  115.34426999599344\n"
          ]
        }
      ],
      "source": [
        "print(\"ElasticNet\")\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html#sklearn.linear_model.ElasticNet\n",
        "reg = linear_model.ElasticNet(alpha=1.0,l1_ratio=0.5, fit_intercept=True).fit(X_train, y_train)\n",
        "y_pred = reg.predict(X_test)\n",
        "muestreMetricas(y_test, y_pred, False)\n",
        "print( \"Coeficientes: \", reg.coef_ )\n",
        "print( \"Intersección: \", reg.intercept_ )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "nfijdF9sXy4Q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wLXYGCMTXy4Q"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}