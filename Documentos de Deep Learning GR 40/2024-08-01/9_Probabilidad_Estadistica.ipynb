{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQr5J5eomeak"
      },
      "source": [
        "# Estadística para Ciencia de los Datos - Lección 1\n",
        "\n",
        "Autor: Saúl Calderón, Juan Esquivel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHZ00bTEHD2N"
      },
      "source": [
        "# Probabilidad\n",
        "\n",
        "La teoría de la probabilidad es de suma importancia para muchos de los\n",
        "algoritmos en el aprendizaje automático y el procesamiento de señales, pues\n",
        "es habitual el lidiar con incertidumbre. El siguiente es un repaso de conceptos\n",
        "básicos de probabilidades. Existen dos ramas o enfoques, la teoría de probabilidades **frecuentista**, basada en frecuencia de ocurrencias de eventos, y la\n",
        "**clásica o axiomática**, que define las probabilidades según otras propiedades\n",
        "del fenómeno."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYbwAPtEK7dF"
      },
      "source": [
        "## Axiomas de la probabilidad\n",
        "\n",
        "\n",
        "\n",
        "*   **Conjunto de muestras $\\Omega$**: Conjunto de todos los resultados posibles de\n",
        "un experimento. El resultado de un experimento puede conceptualizarse\n",
        "como una descripción completa de un estado del mundo real, al finalizar\n",
        "un experimento, y se denota como $\\omega \\in \\Omega$\n",
        "*   **Conjunto de eventos (o espacio de eventos) $\\mathcal{F}$**: Un conjunto A de posibles salidas (una o más salidas) $\\omega$ de un experimento se le llama un **evento**, por lo que entonces A ⊆ Ω. $\\mathcal{F}$ es un espacio de eventos al que\n",
        "pertenecen uno o más eventos $A_i$, por lo que entonces $A_i \\in \\mathcal{F}$. El conjunto $\\mathcal{F}$ satisface las siguientes propiedades:\n",
        "\n",
        "  * El conjunto vacío siempre pertenece a $\\mathcal{F}:\\emptyset \\in \\mathcal{F}$\n",
        "  * $A_1, A_2, ..., A_n \\in \\mathcal{F} \\implies \\cup A_i \\in \\mathcal{F}$\n",
        "  \n",
        "* Propiedades básicas de la función de probabilidad: Una función de densidad de probabilidad $p : \\mathcal{F} \\rightarrow  \\mathbb{R}$:\n",
        "\n",
        "  * $p(A) \\geq 0, \\forall A \\in \\mathcal{F}$\n",
        "  * $p(\\Omega) =1$\n",
        "  * Si $ A_1, A_2, ..., A_n $ son eventos disjuntos $A_i \\cap A_j,$ si $ i \\neq j $ entonces se tiene que: $p(A_i) = \\sum_i^n p(\\cup A_i) $\n",
        "  \n",
        "### Ejemplo 1\n",
        "Defina el evento de tirar un dado de seis caras. El espacio de muestras en este caso viene dado por $\\Omega=\\left\\{ 1,2,3,4,5,6\\right\\} $ con $\\omega_{1}=1,\\omega_{2}=1,\\ldots$ etc. El espacio de eventos más simple es $\\mathcal{F}=\\left\\{ \\emptyset,\\Omega\\right\\} $, para el cual se define  $p\\left(\\emptyset\\right)=0$ y $p\\left(\\Omega\\right)=1$. Otro espacio de eventos posible  $\\mathcal{F}$ es el conjunto de todos los subconjuntos de $\\Omega$. Para este último espacio de eventos, se puede asignar la probabilidad de cada conjunto $A_{i}$ en tal espacio de eventos $\\mathcal{F}$ como $\\frac{k}{n}$donde $k$ es la cantidad de elementos $\\left|A_{i}\\right|$ o cardinalidad y $n=\\left|\\Omega\\right|=6$.  Por ejemplo $p\\left(A_{1}=\\left\\{ 1,2,3,4\\right\\} \\right)=\\frac{4}{6}$\n",
        "\n",
        "###Ejemplo 2\n",
        "Imagine dos cajas, una roja y otra azul. En la caja roja existen 2 manzanas y 6 naranjas, mientras que en la azul existen 3 manzanas y una naranja, como se ilustra en la siguiente figura. Se definen entonces dos espacios de muestras para dos tipos de eventos distintos: $\\Omega_{1}=\\left\\{ r,a\\right\\} $ el cual se refiere a la escogencia de la caja azul o roja y\n",
        "$\\Omega_{2}=\\left\\{ n,v\\right\\} $ el espacio que contiene los resultados experimentales de escoger una bola naranja o verde en cada una de las cajas. El espacio de eventos correspondiente a la escogencia de las cajas se define como $\\mathcal{F}_{1}=\\left\\{ \\emptyset,A_{1}=\\left\\{ r\\right\\} ,A_{2}=\\left\\{ a\\right\\} \\right\\} $, con probabilidades $p\\left(\\emptyset\\right)=0$, $p\\left(A_{1}\\right)=0.4$ y $p\\left(A_{2}\\right)=0.6$. Observe que dado que\n",
        "$A_{1}\\cap A_{2}=\\emptyset$, entonces $p\\left(\\cup A_{i}\\right)=A_{1}+A_{2}=0.6+0.4=1$. Más adelante definiremos el espacio de eventos correspondiente a la escogencia de las pelotas, pues observe que ello depende de la caja escogida, asociado con una **probabilidad condicional**\n",
        "\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1isFSFkup_XGfXd2cTUsFOwTr_09BbiDa)\n",
        "\n",
        "### Propiedades de los eventos\n",
        "* Si $A\\subseteq B\\Rightarrow p\\left(A\\right)\\leq p\\left(B\\right)$\n",
        "* Cota de la intersección $p\\left(A\\cap B\\right)\\leq\\min\\left(p\\left(A\\right)+p\\left(B\\right)\\right)$\n",
        "*Cota de la unión $p\\left(A\\cup B\\right)\\leq p(A)+p(B)$\n",
        "*Complemento $p\\left(\\Omega-A\\right)=p\\left(\\Omega\\backslash A\\right)=1-p(A)$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rdg6UigMX91t"
      },
      "source": [
        "## Variables aleatorias\n",
        "Considere el experimento de tirar una moneda 10 veces, con el objetivo de saber el número de veces que sale corona. En este caso el conjunto de muestras viene dado por $\\Omega=\\left\\{ c,e\\right\\} $. En este caso, el espacio de muestras $\\mathcal{F}$ está dado por todas las secuencias posibles de escudos o coronas que salen al tirar la moneda. Sin embargo, en la práctica, no es necesario saber la probabilidad de obtener una secuencia particular de escudos o coronas. En cambio es más útil expresar lo anterior en términos de una función real que denote por ejemplo la cantidad que aparece cara  después de 10 lanzamientos de la moneda. Tales funciones son conocidas como **variables aleatorias** .\n",
        "Más formalmente, una variable aleatoria $X$ o $X\\left(\\omega\\right)$ para un experimento $\\omega$ es una función definida en un conjunto de muestras $\\Omega$ $X:\\Omega\\rightarrow\\mathbb{R}$, donde se usan letras minúsculas para los valores que la variable aleatoria puede tomar.\n",
        "\n",
        "Una **variable aleatoria discreta** es aquella que solo puede tomar un número finito de valores. El ejemplo de las 10 tiradas de la moneda es un caso en el que se define una variable aleatoria discreta. Formalmente, la probabilidad de que una variable discreta tome un valor $k$ (en el caso de la moneda $c$ o $e$) viene dado por: $ p\\left(X=k\\right):=p\\left(\\omega:X\\left(\\omega\\right)=k\\right)$\n",
        "\n",
        "Una variable aleatoria continua toma una infinita cantidad de número posible, por lo que usualmente se define la probabilidad de que la variable aleatoria tome un valor en el intervalo de $a\\in\\mathbb{R}$ a\n",
        "$b\\in\\mathbb{R}$:$ p\\left(a\\leq X\\leq b\\right):=p\\left(\\left\\{ \\omega:a\\leq X\\left(\\omega\\right)\\leq b\\right\\} \\right).$\n",
        "Un ejemplo de un fenómeno modelado con una variable aleatoria continua,\n",
        " es la probabilidad de que un sensor lumínico reciba una cantidad de lúmenes determinada en un rango $p\\left(l_{1}\\leq X\\leq l_{2}\\right)$.\n",
        " Una notación más resumida permite denotar $p(X)$ como el funcional de la probabilidad de densidad, y $p\\left(X=x\\right)=p(x)$ como la probabilidad de que se tome la muestra $x$.\n",
        "\n",
        " ### Ejemplo\n",
        " Siguiendo el ejemplo de las cajas de naranjas y manzanas ilustrado en la figura anterior, para los espacios $\\Omega_{1}=\\left\\{ r,a\\right\\} $ y\n",
        "$\\Omega_{2}=\\left\\{ n,v\\right\\} $ se definen, respectivamente, las variables aleatorias $C$ y $B$. Así pues, se escriben las probabilidades como $p\\left(C=r\\right)=0.4$ y $p\\left(C=a\\right)=0.6$ para la variable aleatoria $C$.\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMFpJG8UYvY_"
      },
      "source": [
        "## Probabilidad conjunta y condicional\n",
        "\n",
        "Considere dos variables aleatorias $X$ e $Y$, y para cada una de ellas se definen sus codominios $\\Omega_{X}=\\left\\{ x_{1},x_{2},\\ldots x_{M}\\right\\} $ y $\\Omega_{Y}=\\left\\{ y_{1},y_{2},\\ldots y_{L}\\right\\} $. Se realizan un total de $N$ muestras de ambas variables aleatorias donde el número de experimentos en los que la variable aleatoria $X=x_{i}$ y la variable otra variable aleatoria es $Y=y_{j}$ está definido por $n_{i,j}$, de modo que: $N=\\sum_{i}^{M}\\sum_{j}^{L}n_{i,j}.$\n",
        "\n",
        "Además, se define el número de experimentos en las que la variable aleatoria $X=x_{i}$ como $c_{i}=\\sum_{j}^{L}n_{i,j},\n",
        "$ y de manera similar, el número de experimentos en los que la variable aleatoria $Y=y_{j}$ como sigue:$r_{j}=\\sum_{i}^{M}n_{i,j}.$\n",
        "\n",
        "La figura ilustra el ejemplo en el que, para un ejemplo en el que $M=5$ y $L=3$.\n",
        "\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1Rv4RtlSUxKQnxEG8CvVCVdoFRIrx7-2o)\n",
        "\n",
        "### Probabilidad conjunta:\n",
        "Desde un punto de vista probabilístico frecuentista en el que se aproxima\n",
        " una función de densidad de probabilidad, a medida que $N\\rightarrow\\infty$, se define la probabilidad conjunta como la probabilidad de que se tome la muestra $x_{i}$ y la muestra $y_{j}$, y está dada por la fracción de las muestras en la celda $i,j$ dividida por la cantidad total de muestras\n",
        "$N$ y se denota como: $ p\\left(Y=y_{j},X=x_{i}\\right)=p\\left(X=x_{i},Y=y_{j}\\right)=\\frac{n_{i,j}}{N} (1)$\n",
        "\n",
        "### Regla de la suma:\n",
        "La probabilidad de que $X=x_{i}$ sin importar el valor de $Y$ viene dado por: $p\\left(X=x_{i}\\right)=p\\left(X=x_{i},Y=y_{1},\\ldots,y_{L}\\right)=\\sum_{j=1}^{L}p\\left(X=x_{i},Y=y_{j}\\right)=\\frac{c_{i}}{N}(2)$\n",
        "\n",
        "similar con la probabilidad de que $Y=y_{j}$ sin considerar la variable aleatoria $X \\left(Y=y_{j}\\right)=\\frac{r_{j}}{N}$.\n",
        "\n",
        "### Probabilidad condicional:\n",
        "La probabilidad condicional se define como la probabilidad de escoger la muestra $Y=y_{j}$ dado que anteriormente se escogió la muestra $X=x_{i}$ (en otras palabras, se escogió la columna $i$) se define como:\n",
        "$p\\left(Y=y_{j}|X=x_{i}\\right)=\\frac{n_{i,j}}{c_{i}}(3)$ observe que la normalización se hace respecto a la cantidad de veces que se tomó la muestra $X=x_{i}$ sin importar $Y$.\n",
        "\n",
        "### Regla del producto de probabilidad:\n",
        "Tomando las ecuaciones 1, 2 y 3 se puede reescribir: $p\\left(X=x_{i},Y=y_{j}\\right)=\\frac{n_{i,j}}{N}=\\frac{n_{i,j}}{c_{i}}\\cdot\\frac{c_{i}}{N}=p\\left(Y=y_{j}|X=x_{i}\\right)\\cdot p\\left(X=x_{i}\\right)$\n",
        "\n",
        "En resumen se tienen dos reglas fundamentales de la teoría de la probabilidad:\n",
        "* **Regla de la suma**: $p\\left(X\\right)=\\sum_{Y}p\\left(X,Y\\right)$.\n",
        "* **Regla del producto**: $p\\left(X,Y\\right)=p\\left(Y|X\\right)\\cdot p\\left(X\\right)$.\n",
        "* Conmutatividad de la probabilidad conjunta: $p\\left(X,Y\\right)=p\\left(Y,X\\right)$\n",
        "* Conjunción de la regla de la suma, conmutatividad y del producto o cálculo de la **probabilidad marginal**:\n",
        "$p\\left(X\\right)=\\sum_{Y}p\\left(Y,X\\right)\\Rightarrow p\\left(X\\right)=\\sum_{Y}p\\left(X|Y\\right)\\cdot p\\left(Y\\right).$\n",
        "\n",
        "## Teorema de Bayes\n",
        "\n",
        "El teorema de Bayes es de vital importancia para muchos de los algoritmos y técnicas del aprendizaje automático. Para deducirlo, nos basamos en la regla del producto:\n",
        "\n",
        "$p\\left(Y|X\\right)=\\frac{p\\left(X,Y\\right)}{p\\left(X\\right)}$\n",
        "\n",
        "$\n",
        "\\Rightarrow p\\left(X,Y\\right)=p\\left(Y|X\\right)p\\left(X\\right)\n",
        "$\n",
        "\n",
        "$\n",
        "\\Rightarrow p\\left(X\\right)=\\frac{p\\left(X,Y\\right)}{p\\left(Y|X\\right)}$\n",
        "\n",
        "y dada la conmutatividad de la probabilidad conjunta, además de la regla\n",
        " del producto:\n",
        "\n",
        "$\n",
        "p\\left(Y|X\\right)=\\frac{p\\left(X,Y\\right)}{p\\left(X\\right)}=\\frac{p\\left(Y,X\\right)}{p\\left(X\\right)}=\\frac{p\\left(X|Y\\right)\\cdot p\\left(Y\\right)}{p\\left(X\\right)}\n",
        "$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "$\n",
        "\\Rightarrow p\\left(Y|X\\right)=\\frac{p\\left(X|Y\\right)\\cdot p\\left(Y\\right)}{p\\left(X\\right)}\n",
        "$\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1NXuoni7v5q4hTuIl9aq39UVetEhFc31Z)\n",
        "\n",
        "La figura muestra las funciones de densidad de probabilidad, graficadas en cada uno de los ejes, para el caso en el que $M=9$ y $L=2$.\n",
        "\n",
        "\n",
        "* **Fórmula de Bayes**:\n",
        "\n",
        "  $\n",
        "p\\left(H|D\\right)=\\frac{p\\left(D|H\\right)\\cdot p\\left(H\\right)}{p\\left(D\\right)}\n",
        "$\n",
        "\n",
        "* **Probabilidad a priori o marginal**:\n",
        "\n",
        "  Se refiere a la probabilidad $p\\left(H=h\\right)$ de que una hipótesis\n",
        "  $H=h$ se de antes de observar uno o más datos $D=d$ al que puede estar condicionado, por lo que se ignora cualquier dato que lo pueda condicionar.\n",
        "\n",
        "* **Probabilidad a posteriori:**\n",
        "\n",
        "  Corresponde a la probabilidad condicional\n",
        "  $p\\left(H=h|D=d\\right)$\n",
        "  la cual describe la probabilidad de que la hipótesis\n",
        "  $H=h$\n",
        "  se de, dado el suceso anterior del evento o los datos\n",
        "  $D=d$.\n",
        "  \n",
        "  ### Ejemplo\n",
        "  \n",
        "  Retomando el ejemplo de las cajas de frutas, ya se había fijado que:\n",
        "  \n",
        "  $p\\left(C=r\\right)=0.4$\n",
        "\n",
        "  $p\\left(C=a\\right)=0.6$\n",
        "\n",
        "  Para establecer las probabilidades condicionales, en este caso\n",
        "  **no se usa un enfoque frecuentista** , puesto que no tenemos un historial de experimentos previos, en cambio se usa un **enfoque clásico o inferencial** en el que las probabilidades se calculan según características conocidas de antemano para el experimento (en este caso la cantidad de pelotas por caja).   Es por esto que ponemos entonces inferir que:\n",
        "\n",
        "  $\n",
        "  \\begin{array}{c}\n",
        "  p\\left(B=v|C=r\\right)=1/4\\\\\n",
        "  p\\left(B=n|C=r\\right)=3/4\\\\\n",
        "  p\\left(B=v|C=a\\right)=3/4\\\\\n",
        "  p\\left(B=n|C=a\\right)=1/4\n",
        "  \\end{array}\n",
        "  $\n",
        "\n",
        "  Suponga ahora que se desea conocer la probabilidad de obtener una pelota\n",
        "   verde  $p\\left(B=v\\right)$, sin importar la caja de la que viene, o la  **probabilidad a priori** de que $B=v$. Se le llama **probabilidad a priori, pues ningún evento ha sucedido** (escogencia de la caja o de la pelota). Para ello se usa la regla de la ecuación de la probabilidad marginal:\n",
        "   $\n",
        "  p\\left(B=v\\right)=\\sum_{C}p\\left(B=v|C\\right)\\cdot p\\left(C\\right)=p\\left(B=v|C=r\\right)p\\left(C=r\\right)+p\\left(B=v|C=a\\right)p\\left(C=a\\right)$\n",
        "\n",
        "  $\n",
        "  p\\left(B=v\\right)=\\frac{1}{4}\\times\\frac{4}{10}+\\frac{3}{4}\\times\\frac{6}{10}=\\frac{11}{20}$\n",
        "\n",
        "  Finalmente, se desea conocer la probabilidad de que la caja escogida sea roja, dado que se sacó una pelota naranja o la **probabilidad a posteriori** $p\\left(C=r|B=n\\right)$ (se le llama probabilidad a posteriori, pues se asocia con la probabilidad calculada **después de la experiencia** o evento de sacar una pelota naranja), con Bayes, ello viene dado por:\n",
        "\n",
        "  $\n",
        "  p\\left(C=r|B=n\\right)=\\frac{p\\left(B=n|C=r\\right)p\\left(C=r\\right)}{p\\left(B=n\\right)}=\\frac{3}{4}\\times\\frac{4}{10}\\times\\frac{20}{9}=\\frac{2}{3},\n",
        "  $\n",
        "\n",
        "\n",
        "\n",
        "  y por el complemento podemos calcular $p\\left(C=r|B=v\\right)=1-2/3$ .\n",
        "  \n",
        "  ### Independencia de variables aleatorias:\n",
        "  \n",
        "Si dos variables aleatorias $X$ e $Y$son independientes, la probabilidad conjunta de que $X=x$ y $Y=y$ se puede expresar como:\n",
        "\n",
        ">>$p\\left(X,Y\\right)=p\\left(X\\right)p\\left(Y\\right).$\n",
        "\n",
        "\n",
        "\n",
        "Por la regla del producto que establece que\n",
        "$p\\left(X,Y\\right)=p\\left(Y|X\\right)\\cdot p\\left(X\\right)$, tenemos para las variables aleatorias $X$ e $Y$ independientes:\n",
        "\n",
        ">> $\n",
        "p\\left(Y\\right)=p\\left(Y|X\\right)\n",
        "$\n",
        "\n",
        "lo cual se puede leer como que la probabilidad de que $Y=y$ es la misma de que $Y=y$ suceda dado que anteriormente se dió $X=x$, es decir, es independiente. En el ejemplo de las cajas con pelotas, si ambas cajas tienen la misma cantidad de pelotas naranja y verdes, por ejemplo en ambas cajas la mitad de las pelotas son naranjas y la mitad son verdes, tendríamos que:\n",
        "\n",
        ">>$\n",
        "\\begin{array}{c}\n",
        "p\\left(B=v|C=r\\right)=0.5\\\\\n",
        "p\\left(B=n|C=r\\right)=0.5\\\\\n",
        "p\\left(B=v|C=a\\right)=0.5\\\\\n",
        "p\\left(B=n|C=a\\right)=0.5\n",
        "\\end{array}\n",
        "$\n",
        "\n",
        "por lo que entonces por ejemplo, la probabilidad conjunta de que la caja sea roja y la pelota verde está dada por:\n",
        "\n",
        ">>$\n",
        "p\\left(B=v,C=r\\right)=p\\left(B=v|C=r\\right)\\cdot p\\left(C=r\\right)=0.5\\times0.4=0.2 (4)\n",
        "$\n",
        "\n",
        "Para calcular las probabilidades marginales $p\\left(B=v\\right)$ y  $p\\left(B=n\\right)$ se hace:\n",
        "\n",
        ">>$\n",
        "p\\left(B=v\\right)=p\\left(B=v|C=r\\right)p\\left(C=r\\right)+p\\left(B=n|C=a\\right)p\\left(C=a\\right)=0.5\\times0.4+0.5\\times0.6=0.5\n",
        "$\n",
        "\n",
        "y $p\\left(B=n\\right)=1-p\\left(B=v\\right)=0.5$. Es por ello que entonces, para verificar la independencia de la escogencia de la caja con el color de la pelota escogida se hace:\n",
        "\n",
        "$\n",
        "p\\left(B=v\\right)p\\left(C=r\\right)=0.5\\times0.4=0.2=p\\left(B=v,C=r\\right)\n",
        "$\n",
        "(\n",
        "con la última parte de la igualdad deducida en la ecuación (4)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5mBVN4Z0q3p"
      },
      "source": [
        "# 1. Crear una función que genere muestras aleatorias dadas las dos probabilidades de manzana y naranja (i.e. como parametro)\n",
        "# 2. Crear una función que genere múltiples cajas a partir de1 paso 1\n",
        "# 3. Crear funciones para calcular la probabilidad marginal y la probabilidad a posteriori, de acuerdo a las cajas del paso 2\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzhOzfsim15g"
      },
      "source": [
        "## Funciones de densidad de probabilidad y de distribución\n",
        "\n",
        "Una función de densidad de probabilidad con variable continua $x$, $p_{X}\\left(x\\right)\\equiv p\\left(X=x\\right)$ o más resumido como $p\\left(x\\right)$ se define de tal manera si para un intervalo muy pequeño $\\delta x\\rightarrow0$, la probabilidad de que la variable aleatoria $x$ esté en un intervalo $\\left(x,x+\\delta x\\right)$ es también infinitamente pequeña: $p\\left(x\\right)\\delta x\\rightarrow0$. Toda función de densidad de probabilidad debe cumplir las siguientes condiciones básicas:\n",
        "\n",
        ">>$0\\leq p\\left(x\\right)\\leq1$\n",
        "\n",
        ">>$\\int_{-\\infty}^{\\infty}p\\left(x\\right)\\textrm{d}x=1.$\n",
        "\n",
        "La siguiente figura muestra algunas funciones de densidad conocidas.\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1AQH2wfCwXlxiR0zLthYcLcou0ioZQ-Ko)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LZlaHJpm9WE"
      },
      "source": [
        "###Función de distribución\n",
        "\n",
        "La probabilidad de que $x$ se encuentre en el intervalo $\\left(-\\infty,z\\right)$ está dada por la función de distribución acumulativa, o función de distribución $P(z)$ definida como:\n",
        "\n",
        ">>$P_{X}\\left(z\\right)=P\\left(z\\right)=\\int_{-\\infty}^{z}p\\left(x\\right)\\textrm{d}x$\n",
        "\n",
        "\n",
        "\n",
        "lo que implica que\n",
        "\n",
        ">>$P'\\left(x\\right)=p\\left(x\\right),$\n",
        "\n",
        "\n",
        "\n",
        " como se muestra en la siguiente figura.\n",
        "\n",
        "Si la función de densidad $p\\left(x\\right)$ se define como discreta también referida como función de , de manera similar se tienen las siguientes propiedades:\n",
        "\n",
        ">>$0\\leq p\\left[x\\right]\\leq1$\n",
        "\n",
        ">>$\\sum_{x=0}^{\\infty}p\\left[x\\right]=1.$\n",
        "\n",
        ">>$P\\left[z\\right]=\\sum_{x=0}^{z}p\\left[x\\right]$\n",
        "\n",
        "Las siguientes son propiedades de la función de distribución\n",
        "$P\\left(z\\right)$:\n",
        "\n",
        "* $0\\leq P\\left(z\\right)\\leq1$\n",
        "* $\\underset{z\\rightarrow\\infty}{\\lim}P\\left(z\\right)=1$\n",
        "* $\\underset{z\\rightarrow-\\infty}{\\lim}P\\left(z\\right)=0$\n",
        "\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1NUCpcJL1ZhDwTM0N5CLSAE5wUWJJT4MC)\n",
        "\n",
        "\n",
        "La función de densidad de probabilidad con múltiples variables $x_{1},\\ldots x_{D}$ se denota de forma compacta con el vector\n",
        "$\\vec{x}=\\begin{bmatrix}x_{1}\\\\\n",
        "\\vdots\\\\\n",
        "x_{D}\n",
        "\\end{bmatrix}=\\left(x_{1},\\ldots x_{D}\\right)$\n",
        " como la función de densidad de probabilidad conjunta $p\\left(\\vec{x}\\right)=p\\left(x_{1},\\ldots x_{D}\\right)$, por lo que la probablidad de que $\\vec{x}$ se encuentre en un volumen infinitesimal $\\delta\\vec{x}$ está dado por $p\\left(\\vec{x}\\right)\\delta\\vec{x}$ y cumple también las dos propiedades básicas:\n",
        "\n",
        ">>$p\\left(\\vec{x}\\right)\\geq0$\n",
        "\n",
        ">>$\\int_{-\\infty}^{\\infty}p\\left(\\vec{x}\\right)\\textrm{d}\\vec{x}=1.$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKBiznienKGs"
      },
      "source": [
        "### El teorema de Bayes para funciones de densidad\n",
        "\n",
        "Las propiedades de suma, del producto y el teorema de Bayes, aplican también a funciones de densidad de probabilidad, por lo que con $x,y\\in\\mathbb{R}$ se tiene que la probabilidad marginal, conjunta y condicional, respectivamente, están dadas por:\n",
        "\n",
        ">>$\n",
        "p\\left(x\\right)=\\int p\\left(x,y\\right)\\textrm{d}y\n",
        "$\n",
        "\n",
        ">>$\n",
        "p\\left(x,y\\right)=p\\left(y|x\\right)\\,p\\left(x\\right)\n",
        "$\n",
        "\n",
        ">>$\n",
        "p\\left(x|y\\right)=\\frac{p\\left(y|x\\right)\\,p\\left(x\\right)}{p\\left(y\\right)}\n",
        "$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6W4OdsCVnZK-"
      },
      "source": [
        "### Esperanza, varianza y covarianza de una función de densidad de probabilidad\n",
        "\n",
        "El cálculo de momentos estadísticos es una operación muy utilizada en el reconocimiento de patrones, pues permite reducir la dimensionalidad de datos, recabando características importantes como el valor esperado o la varianza.\n",
        "\n",
        "Se define entonces la **esperanza o el valor esperado** de una variable aleatoria $X$ como la sumatoria pesada por la probabilidad de cada valor $x$ que puede tomar tal variable aleatoria (a la izquierda en el caso de ser\n",
        " una variable aleatoria continua, a la derecha discreta):\n",
        "\n",
        ">>$\n",
        "\\mu_{X}=\\mathbb{E}\\left[X\\right]=\\int x\\,p\\left(x\\right)\\textrm{d}x\\qquad\\mu_{X}=\\mathbb{E}\\left[X\\right]=\\sum_{x}x\\,p\\left[x\\right]\n",
        "$\n",
        "\n",
        "En el caso de una función discreta $h\\left[u\\right]$ la cual acumula el valor $x$ generado registrado para el experimento $u$ para un total de\n",
        "$N$ experimentos, generados a partir de la variable aleatoria $X$, la esperanza está dada por:\n",
        "\n",
        ">>$\n",
        "\\mathbb{E}\\left[X\\right]\\cong\\frac{1}{N}\\sum_{u=1}^{N}h\\left[u\\right].(5)\n",
        "$\n",
        "\n",
        "Desde un punto de vista frecuentista, la aproximación de $\\mathbb{E}\\left[X\\right]$ mejora, a medida que $N\\rightarrow\\infty$.\n",
        "\n",
        "Las siguientes son propiedades de la esperanza:\n",
        "\n",
        "* Si $a$ es un escalar, tal que $a\\in\\mathbb{R}$, se tiene que:\n",
        "$\\mathbb{E}\\left[a\\right]=a$\n",
        "* Homogeneidad:\n",
        "$\\mathbb{E}\\left[a\\,X\\right]=a\\,\\mathbb{E}\\left[X\\right].$\n",
        "*Superposición:\n",
        "$\\mathbb{E}\\left[g\\left(X\\right)+f\\left(X\\right)\\right]=\\mathbb{E}\\left[g\\left(X\\right)\\right]+\\mathbb{E}\\left[f\\left(X\\right)\\right].$"
      ]
    }
  ]
}