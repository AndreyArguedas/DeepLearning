{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sPD8sqQXo3_P"
   },
   "source": [
    "# Estadística para Ciencia de los Datos - Lección 2\n",
    "\n",
    "Autor: Saúl Calderón, Juan Esquivel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUrAWwfyzIQ_"
   },
   "source": [
    "# Probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJuoKD9Wogla"
   },
   "source": [
    "## Varianza\n",
    "\n",
    "La varianza de una variable aleatoria $X$ es una medida de la \"concentración\" o dispersión de los datos alrededor de la media. Formalmente la varianza de una variable aleatoria $X$ se define como:\n",
    "\n",
    "\\begin{equation}\n",
    "\\sigma_{X}^{2}\\textrm{=var}\\left[X\\right]=\\mathbb{E}\\left[\\left(X-\\mathbb{E}\\left[X\\right]\\right)^{2}\\right],\n",
    "\\end{equation}\n",
    "\n",
    "lo cual equivale a (por la linealidad de la esperanza y su propiedad de equivalencia en constantes):\n",
    "\n",
    "\\begin{equation}\n",
    "\\\\\n",
    "\\mathbb{E}\\left[\\left(X-\\mathbb{E}\\left[X\\right]\\right)^{2}\\right]=\\mathbb{E}\\left[\\left(X^{2}-2X\\mathbb{E}\\left[X\\right]+\\mathbb{E}\\left[X\\right]^{2}\\right)\\right]\n",
    "\\\\\n",
    "\\Rightarrow\\textrm{var}\\left[X\\right]=\\left(\\mathbb{E}\\left[X^{2}\\right]-\\mathbb{E}\\left[2X\\mathbb{E}\\left[X\\right]\\right]+\\mathbb{E}\\left[\\mathbb{E}\\left[X\\right]^{2}\\right]\\right)\n",
    "\\\\\n",
    "\\Rightarrow\\textrm{var}\\left[X\\right]=\\mathbb{E}\\left[X^{2}\\right]-2\\mathbb{E}\\left[X\\right]^{2}+\\mathbb{E}\\left[X\\right]^{2}\n",
    "\\\\\n",
    "\\Rightarrow\\textrm{var}\\left[X\\right]=\\mathbb{E}\\left[X^{2}\\right]-\\mathbb{E}\\left[X\\right]^{2}\n",
    "\\\\\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Propiedades de la varianza:\n",
    "\n",
    "* Si $a$ es un escalar, tal que $a\\in\\mathbb{R}$, se tiene que: $\\textrm{Var}\\left[a\\right]=0$.\n",
    "*Multiplicación por escalar de la entrada:\n",
    "$\\textrm{Var}\\left[a\\,X\\right]=a^{2}\\textrm{Var}\\left[X\\right]$, $\\forall a\\in\\mathbb{R}$.\n",
    "\n",
    "En el caso de una función discreta $h\\left[u\\right]$ la cual acumula el valor $x$ generado registrado para el experimento $u$ para un total de $N$ experimentos, generados a partir de la variable aleatoria $X$, la varianza está dada por:\n",
    "\n",
    "\\begin{equation}\n",
    "\\sigma_{X}^{2}\\cong\\frac{1}{N-1}\\sum_{u=1}^{N}\\left(h\\left[u\\right]-\\mu_{X}\\right)^{2}.\n",
    "\\end{equation}\n",
    "\n",
    "El estimador anterior se dice que no es \"sesgado\" si la media real no es conocida. Si la media real de la población es conocida, se normaliza por\n",
    "$N$ ( puede ver la demostración de lo anterior  [aquí](http://www.visiondummy.com/2014/03/divide-variance-n-1/)).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RlrvHLoQotIU"
   },
   "source": [
    "### Ejemplo\n",
    "\n",
    "Calcule la media y la varianza de una variable aleatoria uniforme $X$ con una función de densidad $p\\left(x\\right)=1,\\:\\forall x\\in\\left[0,1\\right],\\;0\\:\\textrm{de otro modo}$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbb{E}\\left[X\\right]=\\int_{-\\infty}^{\\infty}x\\,p\\left(x\\right)\\,\\textrm{d}x=\\int_{0}^{1}x\\,\\textrm{d}x=\\frac{1}{2}\n",
    "\\\\\\mathbb{E}\\left[X^{2}\\right]=\\int_{-\\infty}^{\\infty}x^{2}\\,p\\left(x\\right)\\,\\textrm{d}x=\\int_{0}^{1}x^{2}\\,\\textrm{d}x=\\frac{1}{3}\n",
    "\\\\\n",
    "\\textrm{Var}\\left[X\\right]=\\mathbb{E}\\left[X^{2}\\right]-\\mathbb{E}\\left[X\\right]^{2}=\\frac{1}{3}-\\frac{1}{4}=\\frac{1}{12}\n",
    "\\\\\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y5-QvSmTo3Id"
   },
   "source": [
    "## Covarianza\n",
    "\n",
    "Para dos variables aleatorias $X$ e $Y$ se la covarianza como:\n",
    "\n",
    "\\begin{equation}\n",
    "\\Sigma_{X,Y}=\\textrm{cov}\\left(X,Y\\right)=\\mathbb{E}\\left[\\left(X-\\mathbb{E}\\left[X\\right]\\right)\\left(Y-\\mathbb{E}\\left[Y\\right]\\right)\\right]\n",
    "\\end{equation}\n",
    "\n",
    "y mide la variación conjunta de tales variables aleatorias. Para el caso de contar con arreglos de muestras $h\\left[u\\right]$ y $g\\left[u\\right]$ para las variables aleatorias $X$ e $Y$ respectivamente, se tiene que la covarianza de tales variables aleatorias está dada por:\n",
    "\n",
    "\\begin{equation}\n",
    "\\Sigma_{X,Y}\\cong\\frac{1}{N-1}\\sum_{u=1}^{N}\\left(h\\left[u\\right]-\\mu_{X}\\right)\\left(g\\left[u\\right]-\\mu_{Y}\\right).\n",
    "\\end{equation}\n",
    "\n",
    "La matriz de covarianza para $n$ variables aleatorias $X_{1},X_{2},\\ldots,X_{n}$ se define como:\n",
    "\n",
    "\\begin{equation}\n",
    "\\Sigma=\\begin{bmatrix}\\mathbb{E}\\left[\\left(X_{1}-\\mathbb{E}\\left[X_{1}\\right]\\right)\\left(X_{1}-\\mathbb{E}\\left[X_{1}\\right]\\right)\\right] & \\ldots & \\mathbb{E}\\left[\\left(X_{1}-\\mathbb{E}\\left[X_{1}\\right]\\right)\\left(X_{n}-\\mathbb{E}\\left[X_{n}\\right]\\right)\\right]\\\\\n",
    "\\vdots & \\ddots & \\vdots\\\\\n",
    "\\mathbb{E}\\left[\\left(X_{n}-\\mathbb{E}\\left[X_{n}\\right]\\right)\\left(X_{1}-\\mathbb{E}\\left[X_{1}\\right]\\right)\\right] & \\ldots & \\mathbb{E}\\left[\\left(X_{n}-\\mathbb{E}\\left[X_{n}\\right]\\right)\\left(X_{n}-\\mathbb{E}\\left[X_{n}\\right]\\right)\\right]\n",
    "\\end{bmatrix},\n",
    "\\end{equation}\n",
    "\n",
    "observe que en la diagonal de la matriz $\\Sigma$(entrada $\\Sigma_{i,i}$) se tiene que\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbb{E}\\left[\\left(X_{i}-\\mathbb{E}\\left[X_{i}\\right]\\right)\\left(X_{i}-\\mathbb{E}\\left[X_{i}\\right]\\right)\\right]=\\sigma_{X_{i}}^{2},\n",
    "\\end{equation}\n",
    "\n",
    "por lo que entonces la matriz de covarianza se puede reescribir como:\n",
    "\n",
    "\\begin{equation}\n",
    "\\Sigma=\\begin{bmatrix}\\sigma_{X_{1}}^{2} & \\ldots & \\mathbb{E}\\left[\\left(X_{1}-\\mathbb{E}\\left[X_{1}\\right]\\right)\\left(X_{n}-\\mathbb{E}\\left[X_{n}\\right]\\right)\\right]\\\\\n",
    "\\vdots & \\ddots & \\vdots\\\\\n",
    "\\mathbb{E}\\left[\\left(X_{n}-\\mathbb{E}\\left[X_{n}\\right]\\right)\\left(X_{1}-\\mathbb{E}\\left[X_{1}\\right]\\right)\\right] & \\ldots & \\sigma_{X_{n}}^{2}\n",
    "\\end{bmatrix}.\n",
    "\\end{equation}\n",
    "\n",
    "Además, la matriz de covarianza $\\Sigma$ presenta la propiedad de ser simétrica, puesto que\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbb{E}\\left[\\left(X_{i}-\\mathbb{E}\\left[X_{i}\\right]\\right)\\left(X_{j}-\\mathbb{E}\\left[X_{j}\\right]\\right)\\right]=\\mathbb{E}\\left[\\left(X_{j}-\\mathbb{E}\\left[X_{j}\\right]\\right)\\left(X_{i}-\\mathbb{E}\\left[X_{i}\\right]\\right)\\right]\\Rightarrow\\Sigma_{X_{i},X_{j}}=\\Sigma_{X_{j},X_{i}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4yixxkd9pA1f"
   },
   "source": [
    "### Ejemplo\n",
    "\n",
    "Suponga que se desea encontrar la matriz de covarianza para tres variables aleatorias $X_{1},X_{2}$ y $X_{3}$, para las cuales se han recabado los siguientes arreglos de muestras para $N=4$ experimentos, respectivamente:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{array}{c}\n",
    "h_{1}=\\begin{bmatrix}2 & 4 & 6 & 8\\end{bmatrix}\\\\\n",
    "h_{2}=\\begin{bmatrix}4 & 8 & 12 & 16\\end{bmatrix}\\\\\n",
    "h_{3}=\\begin{bmatrix}12 & 10 & 5 & 9\\end{bmatrix}\n",
    "\\end{array}\n",
    "\\end{equation}\n",
    "\n",
    "En términos de muestras se tienen 4 muestras\n",
    "\n",
    "\\begin{equation}\n",
    "U=\\left\\{ \\vec{u}_{1},\\vec{u}_{2},\\vec{u}_{3},\\vec{u}_{4}\\right\\} =\\begin{bmatrix}| & | & | & |\\\\\n",
    "\\vec{u}_{1} & \\vec{u}_{2} & \\vec{u}_{3} & \\vec{u}_{4}\\\\\n",
    "| & | & | & |\n",
    "\\end{bmatrix}=\\begin{bmatrix}2 & 4 & 6 & 8\\\\\n",
    "4 & 8 & 12 & 16\\\\\n",
    "12 & 10 & 5 & 9\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "con $u_{i}\\in\\mathbb{R}^{3}$, donde cada dimensión es una variable aleatoria, y $U\\in\\mathbb{R}^{3\\times4}$.\n",
    "\n",
    "Observe en estos datos, que la dimensión 1 y 2 son combinación lineal para todas las muestras, por lo que la covarianza de ambas dimensiones debe ser alta, no así la dimensión 1 con la 3 o la 2 con la 3.\n",
    "\n",
    "Se procede entonces a calcular las entradas $\\Sigma_{X_{1},X_{2}}$, $\\Sigma_{X_{1},X_{3}}$ y $\\Sigma_{X_{2},X_{3}}$, además de los valores de la diagonal $\\sigma_{X_{1}}^{2}$, $\\sigma_{X_{2}}^{2}$ y $\\sigma_{X_{3}}^{2}$, teniendo en cuenta que $\\mu_{X_{1}}=5$, $\\mu_{X_{2}}=10$ y $\\mu_{X_{3}}=9$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{array}{c}\n",
    "\\Sigma_{X_{1},X_{2}}=\\frac{1}{4-1}\\left(\\left(5-2\\right)\\left(10-4\\right)+\\left(5-4\\right)\\left(10-8\\right)+\\left(5-6\\right)\\left(10-12\\right)+\\left(5-8\\right)\\left(10-16\\right)\\right)\\\\\n",
    "\\Sigma_{X_{1},X_{3}}=\\frac{1}{4-1}\\left(\\left(5-2\\right)\\left(9-12\\right)+\\left(5-4\\right)\\left(9-10\\right)+\\left(5-6\\right)\\left(9-5\\right)+\\left(5-8\\right)\\left(9-9\\right)\\right)\\\\\n",
    "\\Sigma_{X_{2},X_{3}}=\\frac{1}{4-1}\\left(\\left(10-4\\right)\\left(9-12\\right)+\\left(10-8\\right)\\left(9-10\\right)+\\left(10-12\\right)\\left(9-5\\right)+\\left(10-16\\right)\\left(9-9\\right)\\right)\\\\\n",
    "\\sigma_{X_{1}}^{2}=\\frac{1}{4-1}\\left(\\left(5-2\\right)^{2}+\\left(5-4\\right)^{2}+\\left(5-6\\right)^{2}+\\left(5-8\\right)^{2}\\right)\\\\\n",
    "\\sigma_{X_{2}}^{2}=\\frac{1}{4-1}\\left(\\left(10-4\\right)^{2}+\\left(10-8\\right)^{2}+\\left(10-12\\right)^{2}+\\left(10-16\\right)^{2}\\right)\\\\\n",
    "\\sigma_{X_{3}}^{2}=\\frac{1}{4-1}\\left(\\left(9-12\\right)^{2}+\\left(9-10\\right)^{2}+\\left(9-5\\right)^{2}+\\left(9-9\\right)^{2}\\right)\n",
    "\\end{array}\n",
    "\\end{equation}\n",
    "\n",
    "lo cual desarrollado corresponde a:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{array}{c}\n",
    "\\Sigma_{X_{1},X_{2}}=\\frac{1}{3}\\left(3\\cdot6+1\\cdot2+-1\\cdot-2+-3\\cdot-6\\right)=\\frac{40}{3}=13.333\\\\\n",
    "\\Sigma_{X_{1},X_{3}}=\\frac{1}{3}\\left(3\\cdot-3+1\\cdot-1+-1\\cdot4+-3\\cdot0\\right)=-\\frac{14}{3}=-4.667\\\\\n",
    "\\Sigma_{X_{2},X_{3}}=\\frac{1}{3}\\left(6\\cdot-3+2\\cdot-1+-2\\cdot4+-6\\cdot0\\right)=-\\frac{28}{3}=-9.333\\\\\n",
    "\\sigma_{X_{1}}^{2}=\\frac{1}{3}\\left(9+1+1+9\\right)=\\frac{20}{3}=6.667\\\\\n",
    "\\sigma_{X_{2}}^{2}=\\frac{1}{3}\\left(36+4+4+36\\right)=\\frac{80}{3}=26.667\\\\\n",
    "\\sigma_{X_{3}}^{2}=\\frac{1}{3}\\left(9+1+16+0\\right)=\\frac{14}{3}=8.667.\n",
    "\\end{array}\n",
    "\\end{equation}\n",
    "\n",
    "Por lo que se obtiene la matriz de covarianza:\n",
    "\n",
    "\\begin{equation}\n",
    "\\Sigma=\\begin{bmatrix}\\frac{20}{3} & \\frac{40}{3} & -\\frac{14}{3}\\\\\n",
    "\\frac{40}{3} & \\frac{80}{3} & -\\frac{28}{3}\\\\\n",
    "-\\frac{14}{3} & -\\frac{28}{3} & \\frac{14}{3}\n",
    "\\end{bmatrix}=\\begin{bmatrix}6.667 & 13.333 & -4.667\\\\\n",
    "13.333 & 26.666 & -9.333\\\\\n",
    "-4.667 & -9.333 & 8.667\n",
    "\\end{bmatrix}.\n",
    "\\end{equation}\n",
    "\n",
    "Observe que la covarianza más alta es $\\Sigma_{X_{1},X_{2}}$ pues las dimensiones 1 y 2, cuyos datos son generados por las variables aleatorias\n",
    "$X_{1}$ y $X_{2}$, pues los datos siempre covarían positivamente para todas las muestras, en ambas dimensiones. En los otros dos casos, donde la covarianza es negativa, ello denota que cuando en una dimensión los datos varían en una dirección, en la otra los datos varían en dirección contraria.\n",
    "\n",
    "También la matriz de covarianza se puede escribir, para un conjunto de muestras $X=\\left\\{ \\vec{x}_{1},\\vec{x}_{2},\\ldots,\\vec{x}_{m}\\right\\} $, con\n",
    "$\\vec{x}_{i}\\in\\mathbb{R}^{n\\times1}$,  como:\n",
    "\n",
    "\\begin{equation}\n",
    "\\Sigma=\\frac{1}{m}\\sum_{i=1}^{m}\\left(\\vec{x}_{i}-\\vec{\\mu}\\right)\\left(\\vec{x}_{i}-\\vec{\\mu}\\right)^{T}\n",
    "\\end{equation}\n",
    "\n",
    "donde $\\vec{\\mu}\\in\\mathbb{R}^{n\\times1}$ es la muestra promedio del conjunto de datos $X$ (donde cada componente es el valor medio de cada dimensión).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dxDEeNW4paEG"
   },
   "source": [
    "## Coeficiente de correlación de Pearson\n",
    "\n",
    "En el ejemplo anterior, se concluyó que las variables aleatorias\n",
    "$X_{1}$ y $X_{2}$ covarían fuertemente, lo que sugiere una alta correlación entre ambas variables aleatorias. La matriz de Pearson denotada como $\\rho$, permite observar el grado de \"correlación\", normalizando la covarianza, de modo que el coeficiente cumpla que $-1\\leq\\rho\\leq1$. Para dos variables aleatorias $X_{i}$ y $X_{j}$, el coeficiente de Pearson normaliza la covarianza usando la desviación estandar de tales variables aleatorias:\n",
    "\n",
    "\\begin{equation}\n",
    "\\rho_{X_{i},X_{j}}=\\frac{\\textrm{cov}\\left(X_{i},X_{j}\\right)}{\\sigma_{X_{i}}\\sigma_{X_{j}}}\n",
    "\\end{equation}\n",
    "\n",
    "definiendo así la matriz de correlación de Pearson:\n",
    "\\begin{equation}\n",
    "\\Sigma=\\begin{bmatrix}\\frac{\\mathbb{E}\\left[\\left(X_{1}-\\mathbb{E}\\left[X_{1}\\right]\\right)\\left(X_{1}-\\mathbb{E}\\left[X_{1}\\right]\\right)\\right]}{\\sigma_{X_{1}}\\sigma_{X_{1}}} & \\ldots & \\frac{\\mathbb{E}\\left[\\left(X_{1}-\\mathbb{E}\\left[X_{1}\\right]\\right)\\left(X_{n}-\\mathbb{E}\\left[X_{n}\\right]\\right)\\right]}{\\sigma_{X_{1}}\\sigma_{X_{n}}}\\\\\n",
    "\\vdots & \\ddots & \\vdots\\\\\n",
    "\\frac{\\mathbb{E}\\left[\\left(X_{n}-\\mathbb{E}\\left[X_{n}\\right]\\right)\\left(X_{1}-\\mathbb{E}\\left[X_{1}\\right]\\right)\\right]}{\\sigma_{X_{n}}\\sigma_{X_{1}}} & \\ldots & \\frac{\\mathbb{E}\\left[\\left(X_{n}-\\mathbb{E}\\left[X_{n}\\right]\\right)\\left(X_{1}-\\mathbb{E}\\left[X_{1}\\right]\\right)\\right]}{\\sigma_{X_{n}}\\sigma_{X_{n}}}\\ldots\n",
    "\\end{bmatrix},\n",
    "\\end{equation}\n",
    "\n",
    "donde los valores de la diagonal están dados por\n",
    "\n",
    "\\begin{equation}\n",
    "\\rho_{X_{i},X_{j}}=\\frac{\\mathbb{E}\\left[\\left(X_{i}-\\mathbb{E}\\left[X_{i}\\right]\\right)\\left(X_{j}-\\mathbb{E}\\left[X_{j}\\right]\\right)\\right]}{\\sigma_{X_{i}}\\sigma_{X_{j}}}=1\n",
    "\\end{equation}\n",
    "\n",
    "En la siguiente figura se muestra como se comporta el coeficiente de Pearson ante distintas condiciones de dos variables aleatorias $X_{1}$ y $X_{2}$ para los cuales se grafican los datos en los arreglos $h_{1}$ y $h_{2}$.\n",
    "\n",
    "![](https://drive.google.com/uc?export=view&id=1bp6bFNb6C_rSUqeuRGT9DSAmRMGdAttu)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GNdCGSvOpoW-"
   },
   "source": [
    "## La función de densidad Gaussiana\n",
    "\n",
    "La función de densidad Gaussiana es la función de densidad más utilizada en el análisis de datos y el reconocimiento de patrones, pues muchos fenómenos aleatorios naturales (como por ejemplo el peso de las personas en una cierta edad, características físicas en animales y plantas, etc.) se modelan de forma satisfactoria con una función de densidad Gaussiana.\n",
    "\n",
    "La función de densidad Gaussiana es un modelo con dos parámetros: la media $\\mu$ y la dispersión $\\sigma$. Para el caso de una dimensión en la que el codominio está dado por $x\\in\\mathbb{R}$, se tiene que una función de densidad de probabilidad está dada por:\n",
    "\n",
    "\\begin{equation}\n",
    "p\\left(x\\right)=\\mathcal{N}\\left(x|\\mu,\\sigma\\right)=\\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}\\exp\\left(-\\frac{1}{2\\sigma^{2}}\\left(x-\\mu\\right)^{2}\\right),\n",
    "\\end{equation}\n",
    "\n",
    "lo cual expresa la probabilidad de que el valor $X=x$ haya sido generado por un modelo Gaussiano con parámetros $\\theta=\\left(\\mu,\\sigma\\right)$. El coeficiente $\\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}$ normaliza la función de densidad y garantiza el área bajo la curva sea de 1:\n",
    "\n",
    "\\begin{equation}\n",
    "\\int_{-\\infty}^{\\infty}\\mathcal{N}\\left(x|\\mu,\\sigma\\right)\\textrm{d}x=1\n",
    "\\end{equation}\n",
    "\n",
    "y además:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathcal{N}\\left(x|\\mu,\\sigma\\right)>0.\n",
    "\\end{equation}\n",
    "\n",
    "La esperanza de una variable aleatoria $X$ caracterizada por una distribución normal $\\mathcal{N}\\left(x|\\mu,\\sigma\\right)$ viene dada por la media, puesto que:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbb{E}\\left[X\\right]=\\int_{-\\infty}^{\\infty}x\\,\\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}\\exp\\left(-\\frac{1}{2\\sigma^{2}}\\left(x-\\mu\\right)^{2}\\right)\\textrm{d}x=\\mu,\n",
    "\\end{equation}\n",
    "\n",
    "y la esperanza de la variable aleatoria al cuadrado está dada por:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbb{E}\\left[X^{2}\\right]=\\int_{-\\infty}^{\\infty}x^{2}\\,\\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}\\exp\\left(-\\frac{1}{2\\sigma^{2}}\\left(x-\\mu\\right)^{2}\\right)\\textrm{d}x=\\mu^{2}+\\sigma^{2},\n",
    "\\end{equation}\n",
    "\n",
    "por lo cual se deduce que:\n",
    "\n",
    "\\begin{equation}\n",
    "\\textrm{var}\\left[X\\right]=\\mathbb{E}\\left[X^{2}\\right]-\\mathbb{E}\\left[X\\right]^{2}=\\sigma^{2}.\n",
    "\\end{equation}\n",
    "\n",
    "El máximo de la función de densidad de probabilidad Gaussiana, también referido como la **moda**, coincide con la media, como ilustra la la siguente figura\n",
    "\n",
    "![](https://drive.google.com/uc?export=view&id=1lHekBg7C-cdYT8vB0egQ5w8UiVjAPjHi)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbAHhf2zp_py"
   },
   "source": [
    "## Función de verosimilitud\n",
    "\n",
    "Suponga ahora que se cuenta con un arreglo $\\vec{h}=\\left[h_{1},\\ldots,h_{M}\\right]$ de $M$ observaciones discretas sobre el dominio de valores que puede tomar la variable aleatoria $X$.\n",
    "Se supone además que tales observaciones son generadas independientemente, con una misma distribución Gaussiana de parámetros $\\mu$ y $\\sigma$. Para denotar la probabilidad conjunta de que todo el arreglo $\\vec{h}$ haya sido generada por una variable aleatoria Gaussiana con tales parámetros, se escribe la probabilidad conjunta $p\\left(\\vec{h}|\\mu,\\sigma\\right)=p\\left(h_{1},h_{2},\\ldots,h_{m}|\\mu,\\sigma\\right)$, la cual, como vimos anteriormente, en el caso de que los datos sean independientes, corresponde a la multiplicación de las probabilidades marginales, a lo que se le conoce como la **función de verosimilitud**:\n",
    "\n",
    "\\begin{equation}\n",
    "p\\left(\\vec{h}|\\mu,\\sigma\\right)=\\prod_{n=1}^{M}\\mathcal{N}\\left(h_{n}|\\mu,\\sigma\\right) (6)\n",
    "\\end{equation}\n",
    "\n",
    "Dado que lo único que conocemos son los datos en el arreglo $\\vec{h}$, es necesario encontrar los parámetros $\\mu$ y $\\sigma$ que maximicen la función de verosimilitud $p\\left(\\vec{h}|\\mu,\\sigma\\right)$, por lo que entonces, para cada todos los $h_{1},\\ldots h_{M}$ puntos la multiplicatoria debe ser lo máximo posible, lo cual corresponde a lo ilustrado en la siguiente figura\n",
    "\n",
    "![](https://drive.google.com/uc?export=view&id=1qY3OFTAVqVR_0m6UcSsaRizAyoUvW8fN)\n",
    "\n",
    "Para facilitar la maximización de la función de verosimilitud se **utiliza el logaritmo natural**, una función monotónicamente creciente como se muestra en la siguiente figura:\n",
    "\n",
    "![](https://drive.google.com/uc?export=view&id=1YhuV0uE1f__0gYzEuGmwPs0UlVFaH4mG)\n",
    "\n",
    "\n",
    ", por lo que no altera el sentido de la maximización. El logaritmo natural es usual en cálculos que involucran probabilidades, pues evita el problema del \"underflow\" que resulta de calcular el producto de muchos números de magnitud menor que uno. Las siguientes son propiedades del logaritmo natural:\n",
    "\n",
    "* $\\ln\\left(x\\cdot y\\right)=\\ln\\left(x\\right)+\\ln\\left(y\\right)$\n",
    "* $\\ln\\left(e\\right)=1$\n",
    "* $\\ln\\left(x^{n}\\right)=n\\,\\ln\\left(x\\right)$\n",
    "* $\\ln\\left(\\frac{x}{y}\\right)=\\ln\\left(x\\right)-\\ln\\left(y\\right)$\n",
    "* $\\ln\\left(1\\right)=0$\n",
    "* $\\ln\\left(-1\\right)=i\\pi$\n",
    "* $\\ln\\left(x\\right)<\\ln\\left(y\\right),\\forall\\,0<x<y$\n",
    "* $\\frac{d}{dx}\\ln\\left(x\\right)=\\frac{1}{x}$\n",
    "\n",
    "Calculando entonces el logaritmo natural de la función de verosimilitud y usando sus propiedades se obtiene la siguiente expresión simplificada:\n",
    "\n",
    "\\begin{equation}\n",
    "\\ln\\left(p\\left(\\vec{h}|\\mu,\\sigma\\right)\\right)=\\ln\\left(\\prod_{n=1}^{M}\\mathcal{N}\\left(h_{n}|\\mu,\\sigma\\right)\\right)\n",
    "\\\\\n",
    "\\Rightarrow\\ln\\left(p\\left(\\vec{h}|\\mu,\\sigma\\right)\\right)=\\sum_{n=1}^{M}\\ln\\left(\\left(2\\pi\\sigma^{2}\\right)^{-\\frac{1}{2}}\\exp\\left(-\\frac{1}{2\\sigma^{2}}\\left(h_{n}-\\mu\\right)^{2}\\right)\\right)\n",
    "\\\\\n",
    "\\Rightarrow\\ln\\left(p\\left(\\vec{h}|\\mu,\\sigma\\right)\\right)=M\\,\\ln\\left(\\left(2\\pi\\sigma^{2}\\right)^{-\\frac{1}{2}}\\right)+\\sum_{n=1}^{M}\\ln\\left(\\exp\\left(-\\frac{1}{2\\sigma^{2}}\\left(h_{n}-\\mu\\right)^{2}\\right)\\right)\n",
    "\\\\\n",
    "\\Rightarrow\\ln\\left(p\\left(\\vec{h}|\\mu,\\sigma\\right)\\right)=-\\frac{M}{2}\\ln\\left(2\\pi\\sigma^{2}\\right)+-\\frac{1}{2\\sigma^{2}}\\sum_{n=1}^{M}\\left(h_{n}-\\mu\\right)^{2}\n",
    "\\\\\n",
    "\\Rightarrow\\ln\\left(p\\left(\\vec{h}|\\mu,\\sigma\\right)\\right)=-\\frac{1}{2\\sigma^{2}}\\sum_{n=1}^{M}\\left(h_{n}-\\mu\\right)^{2}-\\frac{M}{2}\\ln\\left(2\\pi\\right)-M\\,\\ln\\left(\\sigma\\right).\n",
    "\\end{equation}\n",
    "\n",
    "Para obtener los valores de $\\mu$ y $\\sigma$ que maximicen al logaritmo de la función de verosimilitud, derivamos respecto a $\\mu$ y $\\sigma$ respectivamente:\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{d}{d\\mu}\\ln\\left(p\\left(\\vec{h}|\\mu,\\sigma\\right)\\right)=0\n",
    "\\\\\n",
    "\\Rightarrow\\mu=\\frac{1}{M}\\left(\\sum_{n=1}^{M}h_{n}\\right),\n",
    "\\end{equation}\n",
    "\n",
    "lo cual coinicide con la fórmula de la esperanza planteada en la ecuación 5.\n",
    "\n",
    "Ahora, derivando respecto a la desviación estándar e igualando a cero:\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{d}{d\\sigma}\\ln\\left(p\\left(\\vec{h}|\\mu,\\sigma\\right)\\right)=0\n",
    "\\\\\n",
    "\\Rightarrow\\frac{1}{M}\\sum_{n=1}^{M}\\left(h_{n}-\\mu\\right)^{2}=\\sigma^{2},\n",
    "\\end{equation}\n",
    "\n",
    "lo cual es distinto a lo planteado en la ecuación 6 (normalizado con\n",
    "$\\frac{1}{M-1}$) se obtiene lo que se conoce como un estimador de la varianza\n",
    "*sesgado*, el cual se *sobre-ajusta* a los datos (confía mucho en los datos), por lo que con pocas muestras se recomienda usar el estimador sin sesgo de la ecuación 6.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Vvz3XN11f9z"
   },
   "source": [
    "# Conceptos básicos de estadística\n",
    "\n",
    "Dos de las tareas básicas que trataremos de resolver mediante el uso de estadística son:\n",
    "\n",
    "1. Qué distribución sigue una variable, por ejemplo, la distribución\n",
    "del consumo eléctrico de un hogar en KWs? El responder esta pregunta nos permitirá seleccionar técnicas de clasificación, selección de características, visualización de datos etc.\n",
    "2. Comparar de forma estadísticamente significativa, el efecto de un *tratamiento* o un conjunto de tratamientos sobre una población\n",
    "sin tratamiento. En el plano del aprendizaje automático y las ciencias\n",
    "de los datos, ello es útil para comparar distintos modelos (tratamientos).\n",
    "\n",
    "Las siguientes secciones sientan las bases para el posterior abordaje formal de ambos temas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G0ePhRJs1h8l"
   },
   "source": [
    "## Muestreo aleatorio\n",
    "\n",
    "En muchos problemas reales, no podemos acceder a todas las muestras\n",
    "reales que un fenómeno aleatorio puede generar. Es por ello que se\n",
    "analizan una muestra o conjunto de observaciones, seleccionados de\n",
    "la población en la que estamos interesados por estudiar. Los parámetros\n",
    "reales de una población, muchas veces no es posible obtenerlos por\n",
    "tal limitación, por lo que se calculan los momentos estadísticos en\n",
    "un una **muestra**, como lo ilustra la Figura.\n",
    "\n",
    "![](https://drive.google.com/uc?export=view&id=1mobe3Ts986Ot7GwVUcABzp63j87yAEj-)\n",
    "\n",
    "Observe que en estadística el concepto de muestra se refiere a un conjunto de observaciones. Una **población** consiste en la totalidad de las observaciones\n",
    "generadas a partir de un fenómeno, mientras que una **muestra** es un subconjunto de observaciones seleccionadas de una población.\n",
    "\n",
    "Existen distintos tamaños para una población: de **tamaño finito**\n",
    "(cantidad de empleados en una compañía por ejemplo), o de tamaño infinito\n",
    "(como por ejemplo los **pesos de un modelo**).\n",
    "\n",
    "El modelado paramétrico utiliza una distribución de probabilidad para\n",
    "modelar una población. Por ejemplo, la población de las edades de\n",
    "los usuarios de una aplicación de e-commerce pueden presentar una\n",
    "distribución normal con media $\\mu$ y desviación estándar $\\sigma$.\n",
    "Para una **muestra de la población**, se representan sus dos\n",
    "momentos estadísticos, media $\\overline{x}$ y desviación estándar\n",
    "$s$. La Figura muestra una\n",
    "ilustración del modelo de la población, y el modelo estimado a partir\n",
    "de la muestra, el cual se puede visualizar de forma no paramétrica\n",
    "con el histograma.\n",
    "\n",
    "![](https://drive.google.com/uc?export=view&id=16XllLdqlwyyLnsg6lDgY4Mbw846Pp8ti)\n",
    "\n",
    "En muchas ocasiones es impráctico observar la población completa.\n",
    "La selección de muestras puede introducir un **sesgo** o *bias*, al seleccionarse de forma conveniente un conjunto de observaciones\n",
    "que favorezcan una hipótesis.\n",
    "\n",
    "Suponga que se escogen $n$ muestras $X_{1},X_{2},\\ldots,X_{n}$,\n",
    "de forma aleatoria, bajo condiciones idénticas, con $f\\left(x_{i}\\right)$\n",
    "la función que describe la probabilidad de $x_{i}$ para esa muestra.\n",
    "Se dice que el fenómeno de la variable aleatoria $X$ es ergódico\n",
    "si las distribuciones de las muestras no cambian. Ello implica además,\n",
    "que ambas muestras son independientes, por lo que entonces la probabilidad\n",
    "conjunta:\n",
    "\n",
    "\\begin{equation}\n",
    "f_{X_{1},X_{2},\\ldots,X_{n}}\\left(x_{1},x_{2},\\ldots,x_{n}\\right)=f\\left(x_{1}\\right)f\\left(x_{2}\\right)\\ldots f\\left(x_{n}\\right)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xwo2dLFMwJo2"
   },
   "source": [
    "### Ejemplo\n",
    "Supongamos que deseamos llegar a una conclusión sobre la proporción de personas en los Costa Rica que prefieren\n",
    "una marca particular de automóvil. Sea $p$ el valor desconocido de\n",
    "esta proporción. No es práctico cuestionar a cada individuo en la\n",
    "población para determinar el verdadero valor de $p$.\n",
    "\n",
    "Para hacer una inferencia sobre la verdadera proporción $p$, un procedimiento más razonable consiste en seleccionar una muestra aleatoria (de un tamaño\n",
    "apropiado) y estimar la proporción $\\hat{p}$ de personas en esta\n",
    "muestra que prefiere tal marca de automóvil. La proporción de la muestra,\n",
    "$\\hat{p}$ se calcula dividiendo el número de individuos en la muestra\n",
    "que prefieren la marca de automóviles por el tamaño total de la muestra\n",
    "$n$. Así, $\\hat{p}$ es una función de la valores observados en la\n",
    "muestra aleatoria. Dado que muchas muestras aleatorias son posibles\n",
    "de una población, el valor de $\\hat{p}$ variará de una muestra a\n",
    "otra. Es decir, $\\hat{p}$ es una variable aleatoria. Tal variable\n",
    "aleatoria se conoce como estadística."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k45iqXa_14K2"
   },
   "source": [
    "## Estadísticas descriptivas básicas\n",
    "\n",
    "Además de la **media aritmética** $\\overrightarrow{\\mu}$ para\n",
    "una serie de datos multidimensionales $h$ se definió como:\n",
    "\n",
    "\\begin{equation}\n",
    "\\overrightarrow{\\mu}=\\mathbb{E}\\left[X\\right]\\cong\\frac{1}{N}\\sum_{i=1}^{N}h\\left[i\\right].\n",
    "\\end{equation}\n",
    "\n",
    " y la desviación estándar o la covarianza $\\Sigma$, se definió para\n",
    "datos multidimensionales como:\n",
    "\n",
    "\\begin{equation}\n",
    "\\Sigma=\\begin{bmatrix}\\mathbb{E}\\left[\\left(X_{1}-\\mathbb{E}\\left[X_{1}\\right]\\right)\\left(X_{1}-\\mathbb{E}\\left[X_{1}\\right]\\right)\\right] & \\ldots & \\mathbb{E}\\left[\\left(X_{1}-\\mathbb{E}\\left[X_{1}\\right]\\right)\\left(X_{n}-\\mathbb{E}\\left[X_{n}\\right]\\right)\\right]\\\\\n",
    "\\vdots & \\ddots & \\vdots\\\\\n",
    "\\mathbb{E}\\left[\\left(X_{n}-\\mathbb{E}\\left[X_{n}\\right]\\right)\\left(X_{1}-\\mathbb{E}\\left[X_{1}\\right]\\right)\\right] & \\ldots & \\mathbb{E}\\left[\\left(X_{n}-\\mathbb{E}\\left[X_{n}\\right]\\right)\\left(X_{n}-\\mathbb{E}\\left[X_{n}\\right]\\right)\\right]\n",
    "\\end{bmatrix},\n",
    "\\end{equation}\n",
    "\n",
    "la cual se normaliza por $\\frac{1}{N-1}$ cuando no se calcula para un subconjunto de datos de todos los datos reales.\n",
    "\n",
    "Otra estadística descriptiva es la **moda** $\\overrightarrow{m}$,\n",
    "se define como el valor de mayor ocurrencia, en un conjunto de datos\n",
    "$X$.\n",
    "\n",
    "Por ejemplo, para los siguientes datos multivariable:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{array}{c}\n",
    "\\overrightarrow{x}_{1}=\\left[1\\;2\\right]^{T}\\\\\n",
    "\\overrightarrow{x}_{2}=\\left[1\\;2\\right]^{T}\\\\\n",
    "\\overrightarrow{x}_{3}=\\left[3\\;2\\right]^{T}\\\\\n",
    "\\overrightarrow{x}_{4}=\\left[5\\;3\\right]^{T}\\\\\n",
    "\\overrightarrow{x}_{5}=\\left[8\\;7\\right]^{T}\n",
    "\\end{array}\n",
    "\\end{equation}\n",
    "\n",
    "La moda está dada por $\\overrightarrow{m}=\\left[1\\;2\\right]^{T}$,\n",
    "puesto que para cada dimensión, tales son los valores más frecuentes.\n",
    "\n",
    "La **mediana $\\overrightarrow{\\nu}$** es una estadística de\n",
    "orden de rango, la cual también requiere que se ordenen los datos,\n",
    "para posteriormente escoger el valor en el medio de la secuencia ordenada.\n",
    "\n",
    "En el ejemplo anterior, la mediana viene dada por: $\\overrightarrow{\\nu}=\\left[3\\;2\\right]^{T}$.\n",
    "\n",
    "Tanto la media, como la mediana, y la moda, miden la **tendencia\n",
    "central de los datos**. La mediana no toma en cuenta los valores extremos ni atípicos, a diferencia de la media, la cual puede además producir valores reales y no plausibles en variables discretas.\n",
    "\n",
    "La moda da una mejor aproximación del valor más probable, para muestras con funciones de densidad con inclinación no nula, como lo muestra la Figura, con inclinación positiva y negativa.\n",
    "\n",
    "![](https://drive.google.com/uc?export=view&id=1o2zdU0ZJzHRjUJ8QOxfUm2CKmAy5GeOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZ_7lVN53TjX"
   },
   "source": [
    "## Visualización de muestras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hb6kEO89r_Kn"
   },
   "source": [
    "### Diagramas de caja o *box plot*\n",
    "\n",
    "Los diagramas de caja representan múltiples atributos de los datos al mismo tiempo:\n",
    "\n",
    "- Centro\n",
    "- Variación (anchura de las cajas)\n",
    "- Simetría (o ausencia de ella)\n",
    "- Valores extremos (graficados como puntos separados si se encuentran a más de 1.5 cuartiles de la caja)\n",
    "- Cuartiles 1, 2 y 3\n",
    "- Mínimo y máximo\n",
    "\n",
    "La Figura muestra un conjunto de datos que es relativamente simétrico, con valores extremos representados por puntos.\n",
    "\n",
    "![](https://drive.google.com/uc?export=view&id=1nnNzdVhdOvIeIvkUFXW7p8sNNc0VKkao)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
